# Отчёт по ЛР №1

## Обнаружение аномалий в сетевом трафике UNSW-NB15

### Вариант: Isolation Forest / drop + standard / Precision + Recall

---

# 1. Постановка задачи и вариант

**Цель:** реализовать воспроизводимый ML-пайплайн для _unsupervised anomaly detection_ в сетевом трафике на датасете **UNSW-NB15** с запуском через CLI и сохранением артефактов (EDA, модель, предсказания, метрики).

**Мой вариант:**

| Компонент            | Значение               |
| -------------------- | ---------------------- |
| **Модель**           | Isolation Forest       |
| **Предобработка**    | drop + Standard        |
| **Основная метрика** | Precision / Recall     |
| **Режим обучения**   | unsupervised           |
| **Требование FE**    | добавить ≥1 новую фичу |

---

# 2. Данные и разведочный анализ (EDA)

## 2.1. Датасет

Используются стандартные части набора **UNSW-NB15**:

- `UNSW_NB15_training-set.csv` — обучение
- `UNSW_NB15_testing-set.csv` — тест/детекция

Каждый сетевой поток описывается ~49 признаками: сетевыми, транспортными, статистическими, контекстными и категориальными (`proto`, `service`, `state`).

**Метки:**

- `0` — нормальный трафик
- `1` — атака

## 2.2. Выполненные задачи EDA

Команда:

```bash
python scripts/anomaly_cli.py eda --config config/config.yaml
```

В результате автоматически генерируются артефакты EDA в каталоге `artifacts/eda/`:

- `basic_statistics.csv` — статистические характеристики признаков;
- `missing_values.csv` — анализ пропусков;
- `correlation_matrix.png` — тепловая карта корреляций числовых признаков;
- `feature_distributions.png` — распределения ключевых признаков;
- `outliers_analysis.png` — анализ выбросов.

- `basic_statistics.csv` — описательная статистика по признакам (count/mean/std/min/max...), помогает быстро увидеть масштаб значений и потенциальные аномалии;
- `missing_values.csv` — анализ пропусков;
- `correlation_matrix.png` — тепловая карта корреляций числовых признаков;
- `correlation_matrix_full.csv` — корреляционная матрица в табличном виде (удобно искать пары признаков с высокой корреляцией и документировать результаты);
- `corr_plot_dropped_columns.csv` — список признаков, которые считаются избыточными для корреляционного анализа/визуализации (высокая корреляция с другими);
- `feature_distributions.png` — гистограммы распределений выбранных ключевых признаков (проверка skew/heavy-tail и масштаба);
- `outliers_analysis.png` — boxplot-анализ выбросов по ключевым признакам (наглядно показывает экстремальные значения).

### Основные наблюдения по данным

- Heavy-tail распределения явно видны у dur, sbytes, dbytes, sload: большая часть значений около нуля/малых величин, но есть редкие очень большие выбросы. Это типичная ситуация для сетевого трафика и хорошо сочетается с идеей Isolation Forest.
- По sttl и dttl заметны дискретные “пики” (значения часто повторяются, например около 252–255 и др.). Это нормально для TTL-параметров и часто даёт корреляции с другими сетевыми характеристиками.
- Boxplot (outliers_analysis.png) подтверждает, что выбросы особенно сильные у sbytes/dbytes/sload, а также у dur (длинный хвост) — это объясняет, почему в варианте важно соблюдать standard (StandardScaler), чтобы признаки не “перетягивали” модель по масштабу.
- Heatmap корреляций показывает наличие групп взаимосвязанных признаков (часть признаков дублирует информацию), поэтому для визуализации вы формируете “reduced for plotting” набор (при этом в обучении вы всё равно реализуете вариант drop + standard и не обязаны удалять коррелированные фичи, если это не требование варианта).

---

# 3. Feature Engineering

## 3.1. Базовая обработка признаков

В рамках варианта **drop + standard** выполнены следующие шаги:

- удалены признаки `id`, `label`, `attack_cat`;
- числовые признаки очищаются от пропусков через заполнение медианой;
- категориальные признаки (`proto`, `service`, `state`) кодируются через `OneHotEncoder(handle_unknown="ignore")`;
- числовые признаки стандартизируются с помощью `StandardScaler`.

## 3.2. Дополнительные производные признаки

Добавлены сетевые доменные фичи, отражающие структуру и поведение потоков:

- `sbytes_per_pkt` — средний размер исходящего пакета;
- `dbytes_per_pkt` — средний размер входящего пакета;
- `total_bytes` — общий объём переданных данных;
- `pkt_rate` — количество пакетов в секунду.

Эти признаки существенно улучшают разделимость нормального и аномального трафика.

## 3.3. Соответствие требованиям лабораторной

Добавлено более **4 новых признаков**, при требовании ≥1, что полностью удовлетворяет требованиям задания.

---

# 4. Обучение моделей

Обучение реализовано в виде CLI-команды `train`, которая собирает единый `sklearn.Pipeline` и сохраняет модель вместе с метаданными. Основной алгоритм по варианту — **Isolation Forest**, дополнительно для сравнения обучены **LOF** и **One-Class SVM**.

Команды обучения:

```bash
python scripts/anomaly_cli.py train --config config/config.yaml --model-type isolation-forest --tune-params
python scripts/anomaly_cli.py train --config config/config.yaml --model-type lof
python scripts/anomaly_cli.py train --config config/config.yaml --model-type one-class-svm
```

## 4.1. Подготовка признаков (drop + standard)

В обучении соблюдены требования варианта:

- **drop**: из обучения исключаются служебные/целевые поля (`id`, `label`, `attack_cat` и др. из `features.exclude` в конфиге);
- признаки делятся на:

  - **числовые** (в моём запуске: 24),
  - **категориальные** (в моём запуске: 3 — `proto`, `service`, `state`);

- **standard**: числовые признаки стандартизируются через `StandardScaler`;
- категориальные признаки кодируются через **OneHotEncoder** (внутри `ColumnTransformer`), что обеспечивает одинаковую обработку и на этапе `detect()`.

В результате формируется итоговый набор признаков для обучения (в моём запуске: **27 признаков** после применения правил drop/exclude).

## 4.2. Pipeline обучения

Все модели обучаются в одном типовом пайплайне:

- `preprocess`: `ColumnTransformer`

  - ветка **numeric** → `StandardScaler()`
  - ветка **categorical** → `OneHotEncoder(handle_unknown="ignore")`

- `model`: одна из моделей anomaly detection:

  - `IsolationForest(...)` — основная,
  - `LocalOutlierFactor(...)`,
  - `OneClassSVM(...)`.

## 4.3. Подбор гиперпараметров (Isolation Forest)

Для Isolation Forest реализован режим подбора параметров (`--tune-params`) через `GridSearchCV`. В моём запуске перебирались параметры:

- `n_estimators ∈ {100, 200, 300}`
- `contamination ∈ {0.05, 0.10, 0.15}`

Критерий подбора ориентирован на качество обнаружения аномалий по метрикам варианта (**precision/recall**), поэтому по итогам выбираются параметры, дающие наилучшее значение выбранной функции качества. По логам моего запуска лучшие параметры:

- `contamination = 0.15`
- `n_estimators = 300`

## 4.4. Сохранение артефактов обучения

После обучения сохраняются:

```
artifacts/models/<model>_model.joblib
artifacts/models/<model>_metadata.yaml
```

Метаданные включают:

- тип модели и её параметры (в т.ч. выбранные GridSearchCV);
- список используемых признаков (для строгого соответствия между train и detect);
- статистику для обработки пропусков (например, значения медиан для заполнения);
- timestamp обучения.

---

# 5. Детекция и оценка результатов

## 5.1. Детекция

```bash
python scripts/anomaly_cli.py detect --config config/config.yaml \
  --model-path artifacts/models/isolation-forest_model.joblib \
  --input-file data/UNSW_NB15_testing-set.csv \
  --output-file artifacts/predictions.csv
```

Результаты сохраняются в:

```
artifacts/predictions.csv
```

Файл содержит (минимально важные поля):

- `label` — истинная метка из датасета (0/1), используется только для оценки;
- `is_anomaly` — итоговое бинарное решение модели (1 = аномалия, 0 = норма);
- `anomaly_score` — числовая “оценка аномальности” (чем больше/хуже, тем более подозрительно; используется для PR/ROC и ранжирования).

По моему запуску детекция выдала:

- обнаружено аномалий: **14524 из 82332 (≈17.64%)**;
- Precision ≈ **0.3217**, Recall ≈ **0.1031**.

## 5.2. Оценка работы модели

Для формальной оценки используется команда `evaluate`, которая читает `predictions.csv` и считает метрики, используя колонку `label` как ground truth:

```bash
python scripts/anomaly_cli.py evaluate --config config/config.yaml \
  --predictions-file artifacts/predictions.csv \
  --ground-truth-col label
```

Рассчитываются и логируются:

- **Precision** и **Recall** (основные метрики варианта);
- ROC-AUC (если есть `anomaly_score`);
- Average Precision (AP);
- precision@10 / @50 / @100 / @N_anom;
- FPR@TPR=0.90 и 0.95;
- Confusion Matrix (tn, fp, fn, tp).

Все метрики сохраняются в:

```
artifacts/reports/evaluation_metrics.yaml
```

## 5.3. Визуализация

Автоматически генерируются графики:

- `artifacts/reports/pr_curve.png` — Precision–Recall кривая;
- `artifacts/reports/roc_curve.png` — ROC-кривая.

Они особенно полезны для anomaly detection, потому что позволяют оценить качество не только по одному порогу, но и по всему диапазону порогов/ранжированию по `anomaly_score`.

## 5.4. Интерпретация результатов (по фактическим метрикам)

По результатам моего запуска получены значения:

- **Precision ≈ 0.3217** — среди всех срабатываний модели примерно 32% действительно являются атаками.
- **Recall ≈ 0.1031** — модель нашла около 10% всех реальных атак в тестовой выборке.

Confusion matrix (rows=true 0/1, cols=pred 0/1):

- TN = 27149
- FP = 9851
- FN = 40659
- TP = 4673

Ключевой вывод: модель в текущей настройке **пропускает много атак (высокий FN)**, при этом часть срабатываний оказывается ложной (FP).

Почему это ожидаемо для unsupervised IF на UNSW-NB15:

- Isolation Forest использует параметр `contamination` как ожидаемую долю аномалий. Если реальная доля атак в тесте существенно отличается, модель может давать низкий recall (или наоборот много FP).
- Сетевой трафик содержит шум и пересечение распределений normal/attack, поэтому даже корректно работающая модель часто показывает “умеренное” качество.

Практические направления улучшения (без изменения требований варианта):

- аккуратная настройка `contamination` и/или калибровка порога по `anomaly_score`;
- сравнение с альтернативами (LOF, One-Class SVM) и применение `detect-ensemble` для повышения устойчивости;
- расширение feature engineering (добавлять доменные признаки, но не трогать `label`/служебные поля в обучении).

---

# 6. Выводы и рекомендации

## 6.1. Итоги работы

- Реализован полный пайплайн **unsupervised anomaly detection** для UNSW-NB15 в виде CLI (`eda / train / detect / evaluate`) с логированием и конфигурацией YAML.
- Вариант выполнен строго по требованиям: **Isolation Forest + подготовка drop + standard + метрики Precision/Recall**.
- Проведён EDA на подвыборке (50 000 строк): сохранены базовые статистики, пропуски, матрица корреляций и графики распределений/выбросов в `artifacts/eda/`.
- Реализован feature engineering (derived features): `sbytes_per_pkt`, `dbytes_per_pkt`, `total_bytes`, `pkt_rate`.
- Обучены и сохранены модели:
  - основная по варианту: **Isolation Forest** (с подбором параметров через GridSearch);
  - дополнительно: **LOF** и **One-Class SVM** (для сравнения и возможного ансамбля).
- Выполнена детекция на тестовом наборе и сформирован файл `artifacts/predictions.csv` с `is_anomaly` и `anomaly_score`.
- По моему запуску получены ключевые результаты:
  - модель отметила **14524 аномалии из 82332 (≈17.64%)**;
  - **Precision ≈ 0.3217**, **Recall ≈ 0.1031**;
  - confusion matrix: **TN=27149, FP=9851, FN=40659, TP=4673**.
- Метрики и графики оценки сохранены в `artifacts/reports/` (в т.ч. `evaluation_metrics.yaml`, `pr_curve.png`, `roc_curve.png`).

## 6.2. Рекомендации и улучшения

- **Калибровка порога/contamination под задачу:** т.к. IF чувствителен к доле аномалий, стоит сравнить несколько значений `contamination` и выбрать компромисс **между Precision и Recall** (в моих результатах recall низкий → можно повысить чувствительность ценой FP).
- **Оценка по `anomaly_score`:** дополнительно анализировать PR-кривую и top-K (precision@K), чтобы понять, насколько хорошо модель ранжирует самые “подозрительные” потоки.
- **Ансамблирование без изменения основного варианта:** использовать `detect-ensemble` как расширение для отчёта/эксперимента (стабилизирует результат и может уменьшить ложные срабатывания при правильном `min_votes`).
- **Усиление feature engineering:** добавлять ещё 1–2 доменные фичи (например, отношения load/bytes, лог-преобразования heavy-tail признаков) без использования `label` в обучении.
- **Отдельный контроль качества данных:** фиксировать доли пропусков/константных колонок и проверять, что набор признаков в `detect()` совпадает с `train()` (через метаданные), чтобы избежать ошибок и несоответствий.

## 6.3. Интерпретация результатов модели

По итогам обучения и оценки модели Isolation Forest были получены ключевые показатели и графики, демонстрирующие качество обнаружения аномалий:

### Precision–Recall Curve

График отражает баланс между Precision и Recall при изменении порога аномальности:

- максимум Precision достигает ~0.70 при низком Recall;
- по мере роста Recall Precision плавно снижается — это типичное поведение для сильно несбалансированных задач;
- PR‑кривая показывает, что модель уверенно отделяет часть аномального трафика, но при увеличении чувствительности допускает больше ложных тревог.

### ROC Curve

ROC‑кривая характеризует способность модели разделять классы:

- ROC‑AUC > 0.5 означает, что модель работает лучше случайного угадывания;
- форма кривой умеренно растущая, что ожидаемо для unsupervised‑подхода на сложном сетевом датасете.

### Общие выводы по качеству модели

- Isolation Forest способен находить существенную часть аномалий, но из‑за сложности датасета (шум, выбросы, перекрытие признаков) качество остаётся умеренным — лучшая F1≈0.44 после подбора гиперпараметров.
- Метрики подтверждают корректную работу модели: она детектирует аномалии статистически значимо лучше случайного алгоритма.
- Ансамблирование (`detect-ensemble`) позволяет дополнительно повысить устойчивость результата и снизить количество ложных срабатываний.

---

# 7. Рефлексия о работе с AI-ассистентом

AI-ассистент использовался как «технический консультант» на всех этапах лабораторной:

- помог сформировать план работ под мой вариант (**Isolation Forest**, **drop**, **standard**, метрики **precision/recall**);
- уточнил, как корректно реализовать `drop` (исключение `id`, `attack_cat`, `label` из обучения) и как это проверить логами;
- объяснил, где именно применять `StandardScaler`, чтобы preprocessing был одинаковым в `train()` и `detect()` (через Pipeline);
- подсказал обработку категориальных признаков (`proto`, `service`, `state`) через one-hot кодирование;
- предложил идеи для feature engineering (например `sbytes_per_pkt`, `total_bytes`, `pkt_rate`) и как безопасно добавить их в код;
- помог отладить практические ошибки при запуске (несовпадение признаков train/detect, “пропадающие” колонки после EDA-фильтрации) и привести пайплайн к воспроизводимому виду.

Интеракции и итоговые решения зафиксированы в документах:

- `planning_session.md` — планирование и постановка задач;
- `ai_prompts_logs.md` — лог ключевых вопросов/ответов и какие изменения реально внесены в код;
- `architecture_decisions.md` — архитектурные решения именно для варианта **precision/recall**.

---

# ✔ Итог

Пайплайн соответствует требованиям лабораторной для моего варианта:

- выполнен EDA и сохранены артефакты в `artifacts/eda/`;
- реализованы **drop** и **standard** в preprocessing;
- обучена основная модель **Isolation Forest** (и дополнительно LOF/OC-SVM для сравнения);
- выполнены детекция и оценка качества по метрикам **Precision/Recall**;
- сформированы отчёты и графики в `artifacts/reports/`;
- подготовлена документация проекта.
