# Планирование с AI-ассистентом

## Исходный промпт

```
Мне нужно адаптировать ML-пайплайн для задачи поиска аномалий в сетевом трафике на датасете UNSW-NB15.

НЕ ПИШИ КОД СРАЗУ. Создай детальный план адаптации:

1. Какие алгоритмы anomaly detection подойдут для сетевого трафика?
2. Как обрабатывать 49 признаков UNSW-NB15? Какие из них наиболее важны?
3. Как решить проблему дисбаланса классов (Normal vs Attack)?
4. Какие метрики evaluation подходят для unsupervised anomaly detection?
5. Как адаптировать EDA для анализа сетевых атак?
6. Какие особенности feature engineering нужны для сетевого трафика?

Контекст:
- Датасет: UNSW-NB15 с 49 признаками сетевых потоков
- Цель: unsupervised anomaly detection (игнорируем метки во время обучения)
- Алгоритмы: Isolation Forest, LOF, One-Class SVM
- Требования: production-код с CLI, логированием, конфигурациями

Учти специфику кибербезопасности и особенности сетевого трафика.
```

---

## Ответ AI

### 1. Алгоритмы anomaly detection

Для UNSW-NB15 в контексте кибербезопасности используются три алгоритма:

- **Isolation Forest** — основная модель для моего варианта:

  - масштабируется на большой объём сетевых потоков;
  - устойчив к выбросам и длинным хвостам;
  - выдаёт удобный anomaly score.

- **Local Outlier Factor (LOF)** — для локальных аномалий, запускать на подвыборках или после PCA.

- **One-Class SVM** — для нелинейных границ, применять на ограниченном объёме данных с аккуратной настройкой ядра.

Для моего варианта делаем акцент:

> **Модель:** Isolation Forest (основная)
> **Подготовка:** drop → standard (log + StandardScaler)
> **Метрики:** precision / recall (F1 и ROC-AUC как вспомогательные)

В CLI предусматривается переключатель
`--model-type {isolation-forest, lof, one-class-svm}`,
но основной акцент в отчёте делается на Isolation Forest.

Стартовые настройки Isolation Forest:

- `n_estimators ≈ 300–500`
- `max_samples ≈ 0.6–0.8` или фиксированное число (10–20k)
- `max_features ≈ 0.7–1.0`, `bootstrap = True`
- `random_state = 42`
- `contamination` — стартово 0.08, затем анализ чувствительности в диапазоне 0.05–0.12.

---

### 2. Признаки и препроцессинг UNSW-NB15

**Общие шаги:**

- удалить строки с критическими ошибками и константные признаки;
- разделить признаки на числовые и категориальные;
- настроить единый препроцессинг для всех моделей.

**Числовые признаки**
(например: `dur`, `sbytes`, `dbytes`, `spkts`, `dpkts`, `sload`, `dload`, `sttl`, `dttl`, `sloss`, `dloss`, `ct_*`):

- для хвостатых распределений (`sbytes`, `dbytes`, `sload`, `dload`, `spkts`, `dpkts`, `dur`) — применять `log1p`;
- затем использовать **StandardScaler** для приведения к сопоставимому масштабу.

**Категориальные признаки**
(`proto`, `service`, `state`):

- кодировать с помощью **OneHotEncoder(handle_unknown='ignore')**;
- порядок категорий фиксируется внутри сохранённого препроцессора.

**Ключевые признаки с точки зрения атак:**

- `dur` — длительность соединения;
- объёмы и нагрузки: `sbytes`, `dbytes`, `sload`, `dload`;
- пакеты: `spkts`, `dpkts`;
- TTL: `sttl`, `dttl`;
- контекстные счётчики `ct_*` (частота соединений, сканирование, DoS);
- потери: `sloss`, `dloss`.

---

### 3. Дисбаланс классов и метрики

Обучение — **unsupervised-режиме**, дисбаланс (мало атак, много нормального трафика) учитывается на этапе оценки.

- При обучении Isolation Forest **метки `label` игнорируются**, считаем, что большинство трафика — нормальный.
- при **оценке** и частично в EDA метки применяются для анализа качества.

**Параметр `contamination`:**

- задаёт ожидаемую долю аномалий для Isolation Forest (например, 0.05–0.10);
- служит первичной оценкой, а окончательный рабочий порог выбирается по anomaly score на валидационных данных.

**Метрики для оценки:**

- основные: **Precision, Recall, F1**;
- дополнительные: **ROC-AUC, PR-AUC**, а также **confusion matrix** на выбранном пороге.

Порог anomaly score подбирается по PR-кривой:
одна точка с максимальным F1, другая — с более высоким precision (релевантно для SOC-сценариев).

---

### 4. EDA под сетевые атаки

EDA нацелен на понимание поведения сетевого трафика и атак:

- проверка качества данных: пропуски, константные признаки, объём train/test;
- распределения ключевых числовых признаков (dur, bytes, pkts, sload/dload, ct\_\*)
  в линейном и логарифмическом масштабе;
- анализ категориальных признаков: частоты `proto`, `service`, `state`, редкие значения;
- анализ по меткам:

  - доля Normal vs Attack;
  - при наличии `attack_cat` — распределение по типам атак;

- PCA/UMAP на подвыборке с окраской по `label` — для визуального понимания отделимости атак и выбора разумного диапазона contamination.

Результаты EDA (графики и таблицы) сохраняются в `artifacts/eda/`.

---

### 5. Feature engineering для сетевого трафика

Для усиления сигнала атак добавляются простые derived features:

- **отношения и асимметрия:**

  - `(sbytes + 1) / (dbytes + 1)`
  - `(spkts + 1) / (dpkts + 1)`

- **скорости:**

  - `sbytes / (dur + eps)`
  - `dbytes / (dur + eps)`
  - `spkts / (dur + eps)`
  - `dpkts / (dur + eps)`

Эти признаки:

- рассчитываются поверх исходных;
- проходят те же шаги препроцессинга (лог/скейлинг);
- описываются в `config/config.yaml`, чтобы пайплайн был воспроизводимым.

Цель — сделать всплески объёма, асимметрию и скорость трафика более заметными для моделей anomaly detection.

---

## Уточняющие вопросы и ответы

### Вопрос 1

**AI:** Как связаны `contamination` и выбор рабочего порога anomaly score?

**Ответ:**
`contamination` задаёт приблизительную долю аномалий, которую ожидает Isolation Forest, и используется внутри алгоритма. После обучения:

1. считаем anomaly score на валидационном наборе;
2. по меткам `label` строим PR-кривую;
3. выбираем порог anomaly score, который даёт нужный баланс precision/recall.

Этот порог сохраняется в конфиге и метаданных. Таким образом, `contamination` — внутренняя настройка, а реальный операционный порог выбирается отдельно.

---

### Вопрос 2

**Я:** Что конкретно значит “Подготовка: drop, standard” для UNSW-NB15?

**Ответ:**

- **Drop:**

  - удаляем строки с критическими NaN/ошибками;
  - убираем константные признаки.

- **Standard:**

  - для хвостатых числовых признаков применяем `log1p`;
  - затем StandardScaler для всех числовых признаков;
  - категориальные кодируем One-Hot.

То есть базовая схема:

> **Подготовка:** > `drop → log1p (для хвостатых) → StandardScaler → OneHotEncoder`

---

### Вопрос 3

**AI:** Как обеспечить воспроизводимость экспериментов?

**Ответ:**

- Задать `random_state` в `config.yaml` и использовать его во всех стохастических компонентах.
- Логировать версии библиотек и параметры запуска CLI в `logs/`.
- Сохранять **целый Pipeline** (препроцессор + модель, а при необходимости и порог) в `artifacts/models/` через `joblib`.
- В отчётах фиксировать: конфиг, порог anomaly score, размеры выборок, время запуска.

---

## Финальный план

1. **Инфраструктура и CLI**

   - Настроить структуру каталогов (`data/`, `scripts/`, `config/`, `artifacts/`, `logs/`, `docs/`).
   - Реализовать `anomaly_cli.py` с командами: `eda`, `train`, `detect`, `evaluate`.
   - Включить логирование в `logs/`.

2. **EDA**

   - Проверить качество данных и дисбаланс классов.
   - Построить распределения ключевых признаков и частоты категорий.
   - При необходимости — PCA/UMAP на подвыборке.
   - Сохранить результаты в `artifacts/eda/`.

3. **Подготовка данных (drop, standard)**

   - Реализовать конвейер: `drop → log1p (для хвостатых числовых) → StandardScaler → OneHotEncoder`.
   - Описать используемые признаки и шаги препроцессинга в `config/config.yaml`.

4. **Обучение Isolation Forest**

   - Настроить и обучить Isolation Forest как основную модель.
   - Сохранить Pipeline (препроцессинг + модель) и метаданные в `artifacts/models/`.
   - Опционально: добавить поддержку LOF и One-Class SVM через `--model-type` для сравнения.

5. **Детекция аномалий**

   - Применить сохранённый Pipeline к тестовым данным.
   - Получить anomaly score и бинарные предсказания.
   - Сохранить результаты в `artifacts/predictions.csv`.

6. **Оценка (метрики: precision/recall)**

   - По `predictions.csv` и `label` рассчитать Precision, Recall, F1, ROC-AUC, PR-AUC.
   - Построить confusion matrix, PR/ROC-кривые и сохранить в `artifacts/reports/`.
   - Подобрать и зафиксировать рабочий порог anomaly score.

7. **Документация**

   - Сохранить данный файл как `docs/planning_session.md`.
   - В `docs/architecture_decisions.md` кратко описать:

     - Модель: Isolation Forest;
     - Подготовка: drop, standard;
     - Метрики: precision/recall.

   - Вести `docs/ai_prompts_log.md` с ключевыми промптами и ответами AI.
   - Подготовить `README_submission.md` с описанием пайплайна и основных результатов.

---

## Архитектурные решения

- **Модель:**

  - основная — **Isolation Forest**;
  - LOF и One-Class SVM — опционально, для сравнения через `--model-type`.

- **Подготовка:**

  - **drop → log1p (для хвостатых) → StandardScaler → OneHotEncoder**,
  - реализовано единым `ColumnTransformer + Pipeline`.

- **Метрики:**

  - фокус — **Precision / Recall**;
  - дополнительно — F1, ROC-AUC, PR-AUC, confusion matrix.

- **Работа с метками:**

  - обучение — без меток (unsupervised);
  - EDA и оценка — с метками `label` (и при наличии `attack_cat`) для анализа и метрик.

- **Артефакты и логи:**

  - Pipeline + модель + порог anomaly score — в `artifacts/models/`;
  - метрики и графики — в `artifacts/reports/`;
  - логи запусков — в `logs/`.

- **AI-интеграция:**

  - планирование и ключевые решения зафиксированы в `planning_session.md`;
  - дальнейшие промпты и решения (по отладке и интерпретации) будут отражены в `ai_prompts_log.md` и `architecture_decisions.md`.
