# Архитектурные решения – Вариант Isolation Forest / drop / standard / Precision-Recall

Документ фиксирует ключевые архитектурные и инженерные решения, принятые при реализации пайплайна **anomaly detection** на датасете **UNSW-NB15** в рамках моего варианта.

---

## 1. Выбор алгоритма

### Решение: Isolation Forest как основная модель

**Контекст:** задача обнаружения аномалий в сетевом трафике, высокая размерность признаков, возможные выбросы и смещённые распределения.

**Причины выбора:**

- устойчив к выбросам и heavy-tail распределениям, типичным для сетевого трафика;
- масштабируется на большие объёмы данных;
- подходит для сценария anomaly detection без сильных требований к распределению;
- параметр `contamination` позволяет настраивать долю предполагаемых аномалий.

**Альтернативы:**

- **LOF** — чувствителен к локальной плотности и размеру выборки;
- **One-Class SVM** — хуже масштабируется и требует более тонкой настройки.

---

## 2. Предобработка признаков (drop + standard)

### Решение: Drop + StandardScaler

В соответствии с вариантом применяется:

- `drop` — исключаем признаки, которые не должны участвовать в обучении модели:
  `id`, `label`, `attack_cat` (а также любые служебные/неинформативные поля при необходимости);
- `standard` — масштабирование числовых признаков через **StandardScaler**.

**Обоснование:**

- StandardScaler приводит признаки к сопоставимому масштабу и снижает влияние различий в единицах измерения;
- drop предотвращает утечку целевой информации (`label`) и исключает поля, не отражающие поведение трафика.

---

## 3. Обработка категориальных признаков

### Решение: OneHotEncoder / get_dummies для категориальных полей

Категориальные признаки сетевого трафика (например): `proto`, `service`, `state`.

**Причины выбора:**

- категориальные значения имеют ограниченную мощность (подходят для OHE);
- one-hot кодирование сохраняет информацию без введения ложного порядка категорий;
- использование Pipeline гарантирует одинаковую обработку для train/detect.

---

## 4. Feature Engineering

### Решение: добавление доменно-значимых derived features

Добавлены производные признаки, повышающие разделимость нормального и аномального трафика:

- `sbytes_per_pkt`
- `dbytes_per_pkt`
- `total_bytes`
- `pkt_rate`

**Обоснование:**

- атаки часто проявляются через аномальную интенсивность и структуру пакетов;
- derived-features усиливают сигнал для модели без усложнения алгоритма.

---

## 5. Архитектура CLI-приложения

### Решение: CLI на Typer с разделением на команды

Команды пайплайна:

- `eda` — разведочный анализ и артефакты EDA
- `train` — обучение модели и сохранение артефактов
- `detect` — детекция аномалий на тестовых данных, формирование `predictions.csv`
- `evaluate` — расчет precision/recall и расширенных диагностических метрик

**Причины:**

- четкое разделение ответственности между этапами;
- воспроизводимость экспериментов;
- удобство проверки преподавателем через команды.

---

## 6. Конфигурации и метаданные

### Решение: единый YAML-конфиг для всего пайплайна

Конфигурация содержит:

- пути к данным и артефактам;
- список признаков по группам;
- параметры модели Isolation Forest;
- параметры EDA/визуализаций/логирования.

### Решение: сохранение метаданных модели в YAML

При обучении сохраняются:

- `model_type`
- список используемых `features`
- `model_params`
- `median_map` (значения для заполнения пропусков)
- `timestamp`

**Причины:**

- обеспечивает воспроизводимость эксперимента;
- позволяет корректно выполнять detect на новых данных;
- упрощает дебаг (видно, какие признаки ожидает модель).

---

## 7. Система логирования

### Решение: логирование в консоль и файл

**Обоснование:**

- фиксируется ход выполнения EDA/train/detect/evaluate;
- удобно искать ошибки (например, отсутствие признака в тесте);
- можно сравнивать запуски между собой по логам.

---

## 8. Стратегия оценки

### Основные метрики (по варианту): **Precision и Recall**

Так как задача связана с аномалиями, критичны два типа ошибок:

- **Precision** — насколько «чистыми» являются найденные аномалии (контроль ложных срабатываний FP);
- **Recall** — насколько хорошо модель находит истинные атаки (контроль пропусков FN).

**Почему именно Precision/Recall:**

- в anomaly detection часто важнее контролировать FP и FN отдельно, чем сводить их в одну метрику;
- при дисбалансе классов accuracy малоинформативна;
- precision/recall напрямую интерпретируются в контексте безопасности (шум vs пропуски атак).

**Дополнительно (для анализа качества):**

- confusion matrix;
- PR/ROC-кривые при наличии `anomaly_score` (как диагностические графики);
- ROC-AUC (если возможно корректно вычислить по score).

---

## 9. Структура хранения артефактов

Выбрана единая структура директорий:

- `artifacts/models` — модель (`*.joblib`) и метаданные (`*_metadata.yaml`)
- `artifacts/eda` — статистика и графики EDA
- `artifacts/reports` — метрики и графики оценки
- `logs` или `artifacts/logs` — логи выполнения

**Плюсы:**

- воспроизводимость и прозрачность проекта;
- удобство проверки преподавателем;
- все результаты лежат в ожидаемых местах.
